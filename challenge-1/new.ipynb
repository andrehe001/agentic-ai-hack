{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f010513",
   "metadata": {},
   "source": [
    "# Document Processing with Azure AI Foundry\n",
    "\n",
    "This notebook handles:\n",
    "1. **Document Upload** - Upload policy and claims documents to Azure Blob Storage\n",
    "2. **Text Processing** - Process .md files using AI Foundry GPT-4o-mini\n",
    "3. **OCR Processing** - Extract text from images using AI Foundry vision capabilities\n",
    "4. **Text Enhancement** - Clean and prepare documents for vectorization\n",
    "\n",
    "## Prerequisites\n",
    "- Azure Blob Storage account created\n",
    "- Azure AI Foundry service with GPT-4o-mini model deployed\n",
    "- Environment variables configured in `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c2b1d7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Azure SDK imports\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.core.exceptions import ResourceExistsError, ResourceNotFoundError\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Azure AI Foundry imports\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8039ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Storage configuration - Clean up environment variables\n",
    "    AZURE_STORAGE_CONNECTION_STRING = os.getenv('AZURE_STORAGE_CONNECTION_STRING', '').strip('\"')\n",
    "    AZURE_STORAGE_ACCOUNT_NAME = os.getenv('AZURE_STORAGE_ACCOUNT_NAME', '').strip('\"').strip()\n",
    "    AZURE_STORAGE_ACCOUNT_KEY = os.getenv('AZURE_STORAGE_ACCOUNT_KEY', '').strip('\"')\n",
    "    \n",
    "    # Azure AI Foundry configuration\n",
    "    AI_FOUNDRY_ENDPOINT = os.getenv('AI_FOUNDRY_ENDPOINT', '').strip('\"')\n",
    "    AI_FOUNDRY_KEY = os.getenv('AI_FOUNDRY_KEY', '').strip('\"')\n",
    "    AI_FOUNDRY_HUB_NAME = os.getenv('AI_FOUNDRY_HUB_NAME', '').strip('\"')\n",
    "    \n",
    "    # Model deployment names in AI Foundry\n",
    "    CHAT_MODEL_DEPLOYMENT = 'gpt-4o-mini'  # This should match your deployment name\n",
    "    EMBEDDING_MODEL_DEPLOYMENT = 'text-embedding-ada-002'  # This should match your deployment name\n",
    "    \n",
    "    # Container names\n",
    "    POLICIES_CONTAINER = 'policies'\n",
    "    CLAIMS_CONTAINER = 'claims'\n",
    "    PROCESSED_CONTAINER = 'processed-documents'\n",
    "    \n",
    "    # Local data paths\n",
    "    DATA_DIR = Path('data')\n",
    "    POLICIES_DIR = DATA_DIR / 'policies'\n",
    "    CLAIMS_DIR = DATA_DIR / 'claims'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5289471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully!\n",
      "üìÅ Policies directory: data\\policies\n",
      "üìÅ Claims directory: data\\claims\n",
      "ü§ñ AI Foundry Hub: msagthack-aifoundry-wuwcap2zryvge\n",
      "üîó AI Foundry Endpoint: https://msagthack-aifoundry-wuwcap2zryvge.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "# Clean and validate configuration\n",
    "def clean_config():\n",
    "    \"\"\"Clean and validate configuration values\"\"\"\n",
    "    # Remove any extra quotes or whitespace\n",
    "    for attr_name in dir(Config):\n",
    "        if not attr_name.startswith('_') and isinstance(getattr(Config, attr_name), str):\n",
    "            value = getattr(Config, attr_name).strip().strip('\"').strip(\"'\")\n",
    "            setattr(Config, attr_name, value)\n",
    "\n",
    "clean_config()\n",
    "\n",
    "# Validate configuration\n",
    "required_vars = [\n",
    "    ('AZURE_STORAGE_CONNECTION_STRING', Config.AZURE_STORAGE_CONNECTION_STRING),\n",
    "    ('AI_FOUNDRY_ENDPOINT', Config.AI_FOUNDRY_ENDPOINT),\n",
    "    ('AI_FOUNDRY_KEY', Config.AI_FOUNDRY_KEY)\n",
    "]\n",
    "\n",
    "missing_vars = []\n",
    "for var_name, var_value in required_vars:\n",
    "    if not var_value or var_value == '':\n",
    "        missing_vars.append(var_name)\n",
    "\n",
    "if missing_vars:\n",
    "    print(\"‚ùå Missing environment variables. Please check your .env file.\")\n",
    "    print(\"Missing variables:\")\n",
    "    for var in missing_vars:\n",
    "        print(f\"  - {var}\")\n",
    "else:\n",
    "    print(\"‚úÖ Configuration loaded successfully!\")\n",
    "    print(f\"üìÅ Policies directory: {Config.POLICIES_DIR}\")\n",
    "    print(f\"üìÅ Claims directory: {Config.CLAIMS_DIR}\")\n",
    "    print(f\"ü§ñ AI Foundry Hub: {Config.AI_FOUNDRY_HUB_NAME}\")\n",
    "    print(f\"üîó AI Foundry Endpoint: {Config.AI_FOUNDRY_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba204a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing Azure clients...\n",
      "üîë Trying connection string authentication...\n",
      "‚ùå Connection string failed: <urllib3.connection.HTTPSConnection object at 0x00000191E55DE990>: Failed to resolve 'msagthacksawuwcap2zryvge.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\n",
      "üîë Trying account name and key authentication...\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "\n",
    "\n",
    "# Initialize Azure clients with improved error handling\n",
    "def initialize_clients():\n",
    "    \"\"\"Initialize Azure service clients with comprehensive error handling\"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Initializing Azure clients...\")\n",
    "        \n",
    "        # Initialize Blob Storage client with multiple fallback methods\n",
    "        blob_service_client = None\n",
    "        \n",
    "        # Method 1: Try connection string\n",
    "        if Config.AZURE_STORAGE_CONNECTION_STRING:\n",
    "            try:\n",
    "                print(\"üîë Trying connection string authentication...\")\n",
    "                blob_service_client = BlobServiceClient.from_connection_string(\n",
    "                    Config.AZURE_STORAGE_CONNECTION_STRING\n",
    "                )\n",
    "                # Test the connection\n",
    "                account_info = blob_service_client.get_account_information()\n",
    "                print(\"‚úÖ Storage client initialized with connection string!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Connection string failed: {e}\")\n",
    "                blob_service_client = None\n",
    "        \n",
    "        # Method 2: Try account name and key\n",
    "        if not blob_service_client and Config.AZURE_STORAGE_ACCOUNT_NAME and Config.AZURE_STORAGE_ACCOUNT_KEY:\n",
    "            try:\n",
    "                print(\"üîë Trying account name and key authentication...\")\n",
    "                blob_service_client = BlobServiceClient(\n",
    "                    account_url=f\"https://{Config.AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "                    credential=Config.AZURE_STORAGE_ACCOUNT_KEY\n",
    "                )\n",
    "                # Test the connection\n",
    "                account_info = blob_service_client.get_account_information()\n",
    "                print(\"‚úÖ Storage client initialized with account key!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Account key failed: {e}\")\n",
    "                blob_service_client = None\n",
    "        \n",
    "        # Method 3: Try default credentials (if managed identity is available)\n",
    "        if not blob_service_client and Config.AZURE_STORAGE_ACCOUNT_NAME:\n",
    "            try:\n",
    "                print(\"üîë Trying default Azure credentials...\")\n",
    "                credential = DefaultAzureCredential()\n",
    "                blob_service_client = BlobServiceClient(\n",
    "                    account_url=f\"https://{Config.AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "                    credential=credential\n",
    "                )\n",
    "                # Test the connection\n",
    "                account_info = blob_service_client.get_account_information()\n",
    "                print(\"‚úÖ Storage client initialized with default credentials!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Default credentials failed: {e}\")\n",
    "                blob_service_client = None\n",
    "        \n",
    "        if not blob_service_client:\n",
    "            print(\"‚ùå Failed to initialize storage client with any method\")\n",
    "        \n",
    "        # Initialize AI Foundry client\n",
    "        ai_client = None\n",
    "        if Config.AI_FOUNDRY_ENDPOINT and Config.AI_FOUNDRY_KEY:\n",
    "            try:\n",
    "                print(\"ü§ñ Initializing AI Foundry client...\")\n",
    "                ai_client = ChatCompletionsClient(\n",
    "                    endpoint=Config.AI_FOUNDRY_ENDPOINT,\n",
    "                    credential=AzureKeyCredential(Config.AI_FOUNDRY_KEY)\n",
    "                )\n",
    "                print(\"‚úÖ AI Foundry client initialized successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error initializing AI Foundry client: {e}\")\n",
    "                ai_client = None\n",
    "        \n",
    "        return blob_service_client, ai_client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during client initialization: {e}\")\n",
    "        return None, None\n",
    "\n",
    "blob_service_client, ai_client = initialize_clients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9abc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running enhanced container creation...\n",
      "üîç Testing storage account connection...\n",
      "‚úÖ Connected to storage account successfully\n",
      "   Account kind: StorageV2\n",
      "   SKU name: Standard_RAGRS\n",
      "\n",
      "üîç Checking existing containers...\n",
      "‚úÖ Found 3 existing containers: ['claims', 'policies', 'processed-documents']\n",
      "‚ÑπÔ∏è Container 'policies' already exists\n",
      "‚ÑπÔ∏è Container 'claims' already exists\n",
      "‚ÑπÔ∏è Container 'processed-documents' already exists\n",
      "\n",
      "üìä Container Creation Summary:\n",
      "   ‚úÖ Successful: 3 - ['policies', 'claims', 'processed-documents']\n",
      "   ‚ùå Failed: 0 - []\n"
     ]
    }
   ],
   "source": [
    "# Enhanced container creation with better error handling\n",
    "def create_containers_enhanced(blob_service_client):\n",
    "    \"\"\"Create blob storage containers with enhanced error handling\"\"\"\n",
    "    \n",
    "    if not blob_service_client:\n",
    "        print(\"‚ùå No blob service client available\")\n",
    "        return False\n",
    "    \n",
    "    # First, test the connection\n",
    "    try:\n",
    "        print(\"üîç Testing storage account connection...\")\n",
    "        account_info = blob_service_client.get_account_information()\n",
    "        print(f\"‚úÖ Connected to storage account successfully\")\n",
    "        print(f\"   Account kind: {account_info.get('account_kind', 'Unknown')}\")\n",
    "        print(f\"   SKU name: {account_info.get('sku_name', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to connect to storage account: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test listing existing containers\n",
    "    try:\n",
    "        print(\"\\nüîç Checking existing containers...\")\n",
    "        existing_containers = []\n",
    "        for container in blob_service_client.list_containers():\n",
    "            existing_containers.append(container.name)\n",
    "        print(f\"‚úÖ Found {len(existing_containers)} existing containers: {existing_containers}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to list containers: {e}\")\n",
    "        print(\"   This might indicate insufficient permissions\")\n",
    "    \n",
    "    # Try to create containers\n",
    "    containers = [\n",
    "        Config.POLICIES_CONTAINER,\n",
    "        Config.CLAIMS_CONTAINER,\n",
    "        Config.PROCESSED_CONTAINER\n",
    "    ]\n",
    "    \n",
    "    created_containers = []\n",
    "    failed_containers = []\n",
    "    \n",
    "    for container_name in containers:\n",
    "        try:\n",
    "            # Check if container already exists first\n",
    "            container_client = blob_service_client.get_container_client(container_name)\n",
    "            \n",
    "            try:\n",
    "                # Try to get container properties (this will fail if it doesn't exist)\n",
    "                properties = container_client.get_container_properties()\n",
    "                print(f\"‚ÑπÔ∏è Container '{container_name}' already exists\")\n",
    "                created_containers.append(container_name)\n",
    "                continue\n",
    "            except ResourceNotFoundError:\n",
    "                # Container doesn't exist, try to create it\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                # Other error, container might exist but we can't access it\n",
    "                print(f\"‚ö†Ô∏è Container '{container_name}' exists but access check failed: {e}\")\n",
    "                created_containers.append(container_name)\n",
    "                continue\n",
    "            \n",
    "            # Create the container\n",
    "            print(f\"üî® Creating container '{container_name}'...\")\n",
    "            container_client.create_container()\n",
    "            print(f\"‚úÖ Container '{container_name}' created successfully\")\n",
    "            created_containers.append(container_name)\n",
    "            \n",
    "        except ResourceExistsError:\n",
    "            print(f\"‚ÑπÔ∏è Container '{container_name}' already exists\")\n",
    "            created_containers.append(container_name)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with container '{container_name}': {e}\")\n",
    "            failed_containers.append((container_name, str(e)))\n",
    "            \n",
    "            # Additional diagnostics for authorization errors\n",
    "            if \"AuthorizationFailure\" in str(e) or \"Forbidden\" in str(e):\n",
    "                print(f\"   üîç Authorization issue detected for '{container_name}'\")\n",
    "                print(f\"   This could be due to:\")\n",
    "                print(f\"   - Storage account access keys disabled\")\n",
    "                print(f\"   - Network access restrictions\")\n",
    "                print(f\"   - Storage account permissions\")\n",
    "                print(f\"   - Try using Azure CLI: az storage container create --name {container_name} --account-name {Config.AZURE_STORAGE_ACCOUNT_NAME}\")\n",
    "    \n",
    "    print(f\"\\nüìä Container Creation Summary:\")\n",
    "    print(f\"   ‚úÖ Successful: {len(created_containers)} - {created_containers}\")\n",
    "    print(f\"   ‚ùå Failed: {len(failed_containers)} - {[name for name, _ in failed_containers]}\")\n",
    "    \n",
    "    return len(failed_containers) == 0\n",
    "\n",
    "# Run the enhanced container creation\n",
    "if blob_service_client:\n",
    "    print(\"üöÄ Running enhanced container creation...\")\n",
    "    success = create_containers_enhanced(blob_service_client)\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\nüìù CONTAINER CREATION SUGGESTIONS\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"If container creation failed, try these solutions:\")\n",
    "        print(\"\\n1. **Azure Portal Method:**\")\n",
    "        print(\"   - Go to https://portal.azure.com\")\n",
    "        print(f\"   - Navigate to storage account: {Config.AZURE_STORAGE_ACCOUNT_NAME}\")\n",
    "        print(\"   - Go to 'Containers' in the left menu\")\n",
    "        print(\"   - Click '+ Container' and create these containers:\")\n",
    "        print(\"     ‚Ä¢ policies\")\n",
    "        print(\"     ‚Ä¢ claims\") \n",
    "        print(\"     ‚Ä¢ processed-documents\")\n",
    "        print(\"   - Set 'Public access level' to 'Private' for all containers\")\n",
    "        \n",
    "        print(\"\\n2. **Azure CLI Method:**\")\n",
    "        print(\"   Run these commands in Azure CLI:\")\n",
    "        for container in [Config.POLICIES_CONTAINER, Config.CLAIMS_CONTAINER, Config.PROCESSED_CONTAINER]:\n",
    "            print(f\"   az storage container create --name {container} --account-name {Config.AZURE_STORAGE_ACCOUNT_NAME} --account-key {Config.AZURE_STORAGE_ACCOUNT_KEY}\")\n",
    "else:\n",
    "    print(\"‚ùå No blob service client available - please check your configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cc0519",
   "metadata": {},
   "source": [
    "## 3. Document Upload Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document uploader initialized!\n"
     ]
    }
   ],
   "source": [
    "class DocumentUploader:\n",
    "    def __init__(self, blob_service_client):\n",
    "        self.blob_service_client = blob_service_client\n",
    "    \n",
    "    def upload_file(self, file_path: Path, container_name: str, blob_name: str = None) -> bool:\n",
    "        \"\"\"Upload a single file to blob storage\"\"\"\n",
    "        if not self.blob_service_client:\n",
    "            print(\"‚ùå No blob service client available\")\n",
    "            return False\n",
    "            \n",
    "        if blob_name is None:\n",
    "            blob_name = file_path.name\n",
    "            \n",
    "        try:\n",
    "            blob_client = self.blob_service_client.get_blob_client(\n",
    "                container=container_name, \n",
    "                blob=blob_name\n",
    "            )\n",
    "            \n",
    "            with open(file_path, 'rb') as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "            \n",
    "            print(f\"‚úÖ Uploaded: {file_path.name} ‚Üí {container_name}/{blob_name}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading {file_path.name}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def upload_directory(self, directory_path: Path, container_name: str) -> Dict[str, bool]:\n",
    "        \"\"\"Upload all files from a directory to blob storage\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        if not directory_path.exists():\n",
    "            print(f\"‚ùå Directory not found: {directory_path}\")\n",
    "            return results\n",
    "        \n",
    "        files = list(directory_path.glob('*'))\n",
    "        if not files:\n",
    "            print(f\"‚ÑπÔ∏è No files found in {directory_path}\")\n",
    "            return results\n",
    "        \n",
    "        print(f\"üì§ Uploading {len(files)} files from {directory_path} to {container_name}...\")\n",
    "        \n",
    "        for file_path in tqdm(files, desc=\"Uploading files\"):\n",
    "            if file_path.is_file():\n",
    "                success = self.upload_file(file_path, container_name)\n",
    "                results[file_path.name] = success\n",
    "        \n",
    "        successful_uploads = sum(results.values())\n",
    "        print(f\"\\nüìä Upload Summary: {successful_uploads}/{len(results)} files uploaded successfully\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def list_blobs(self, container_name: str) -> List[str]:\n",
    "        \"\"\"List all blobs in a container\"\"\"\n",
    "        if not self.blob_service_client:\n",
    "            print(\"‚ùå No blob service client available\")\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            container_client = self.blob_service_client.get_container_client(container_name)\n",
    "            blob_list = container_client.list_blobs()\n",
    "            return [blob.name for blob in blob_list]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing blobs in {container_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "# Initialize uploader\n",
    "uploader = None\n",
    "if blob_service_client:\n",
    "    uploader = DocumentUploader(blob_service_client)\n",
    "    print(\"‚úÖ Document uploader initialized!\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize uploader - no blob service client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881177a",
   "metadata": {},
   "source": [
    "## 4. Upload Documents to Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d5fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Uploading Policy Documents...\n",
      "==================================================\n",
      "üì§ Uploading 5 files from data\\policies to policies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: commercial_auto_policy.md ‚Üí policies/commercial_auto_policy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: comprehensive_auto_policy.md ‚Üí policies/comprehensive_auto_policy.md\n",
      "‚úÖ Uploaded: high_value_vehicle_policy.md ‚Üí policies/high_value_vehicle_policy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: liability_only_policy.md ‚Üí policies/liability_only_policy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: motorcycle_policy.md ‚Üí policies/motorcycle_policy.md\n",
      "\n",
      "üìä Upload Summary: 5/5 files uploaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Policies in storage (5 files):\n",
      "  ‚Ä¢ commercial_auto_policy.md\n",
      "  ‚Ä¢ comprehensive_auto_policy.md\n",
      "  ‚Ä¢ high_value_vehicle_policy.md\n",
      "  ‚Ä¢ liability_only_policy.md\n",
      "  ‚Ä¢ motorcycle_policy.md\n"
     ]
    }
   ],
   "source": [
    "# Upload policy documents\n",
    "if uploader:\n",
    "    print(\"üìÑ Uploading Policy Documents...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    policy_results = uploader.upload_directory(Config.POLICIES_DIR, Config.POLICIES_CONTAINER)\n",
    "\n",
    "    # Show uploaded policies\n",
    "    policy_blobs = uploader.list_blobs(Config.POLICIES_CONTAINER)\n",
    "    print(f\"\\nüìã Policies in storage ({len(policy_blobs)} files):\")\n",
    "    for blob in policy_blobs:\n",
    "        print(f\"  ‚Ä¢ {blob}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot upload policies - no uploader available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d99467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üñºÔ∏è Uploading Claims Documents...\n",
      "==================================================\n",
      "üì§ Uploading 6 files from data\\claims to claims...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:00<00:00,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: crash1.jpg ‚Üí claims/crash1.jpg\n",
      "‚úÖ Uploaded: crash2.jpg ‚Üí claims/crash2.jpg\n",
      "‚úÖ Uploaded: crash3.jpg ‚Üí claims/crash3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: crash4.jpeg ‚Üí claims/crash4.jpeg\n",
      "‚úÖ Uploaded: crash5.jpg ‚Üí claims/crash5.jpg\n",
      "‚úÖ Uploaded: invoice.png ‚Üí claims/invoice.png\n",
      "\n",
      "üìä Upload Summary: 6/6 files uploaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Claims in storage (6 files):\n",
      "  ‚Ä¢ crash1.jpg\n",
      "  ‚Ä¢ crash2.jpg\n",
      "  ‚Ä¢ crash3.jpg\n",
      "  ‚Ä¢ crash4.jpeg\n",
      "  ‚Ä¢ crash5.jpg\n",
      "  ‚Ä¢ invoice.png\n"
     ]
    }
   ],
   "source": [
    "# Upload claims documents\n",
    "if uploader:\n",
    "    print(\"\\nüñºÔ∏è Uploading Claims Documents...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    claims_results = uploader.upload_directory(Config.CLAIMS_DIR, Config.CLAIMS_CONTAINER)\n",
    "\n",
    "    # Show uploaded claims\n",
    "    claims_blobs = uploader.list_blobs(Config.CLAIMS_CONTAINER)\n",
    "    print(f\"\\nüìã Claims in storage ({len(claims_blobs)} files):\")\n",
    "    for blob in claims_blobs:\n",
    "        print(f\"  ‚Ä¢ {blob}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot upload claims - no uploader available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a9339",
   "metadata": {},
   "source": [
    "## 5. Document Processing with Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc57fd9",
   "metadata": {},
   "source": [
    "## 5A. Image Processing with Azure AI Foundry Vision\n",
    "Process .jpg files from claims container using multimodal GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, ai_client, blob_service_client):\n",
    "        self.ai_client = ai_client\n",
    "        self.blob_service_client = blob_service_client\n",
    "    \n",
    "    def get_blob_content(self, container_name: str, blob_name: str) -> bytes:\n",
    "        \"\"\"Download blob content as bytes\"\"\"\n",
    "        if not self.blob_service_client:\n",
    "            raise Exception(\"No blob service client available\")\n",
    "            \n",
    "        blob_client = self.blob_service_client.get_blob_client(\n",
    "            container=container_name, \n",
    "            blob=blob_name\n",
    "        )\n",
    "        blob_data = blob_client.download_blob()\n",
    "        return blob_data.readall()\n",
    "    \n",
    "    def encode_image_to_base64(self, image_bytes: bytes) -> str:\n",
    "        \"\"\"Encode image bytes to base64 string\"\"\"\n",
    "        return base64.b64encode(image_bytes).decode('utf-8')\n",
    "    \n",
    "    def extract_text_from_image(self, container_name: str, blob_name: str) -> Dict:\n",
    "        \"\"\"Extract text from image using AI Foundry GPT-4o vision capabilities\"\"\"\n",
    "        try:\n",
    "            print(f\"üñºÔ∏è Processing image: {blob_name}...\")\n",
    "            \n",
    "            # Download image content\n",
    "            image_bytes = self.get_blob_content(container_name, blob_name)\n",
    "            base64_image = self.encode_image_to_base64(image_bytes)\n",
    "            # Determine image format from file extension\n",
    "            file_extension = Path(blob_name).suffix.lower()\n",
    "            if file_extension == \".jpg\" or file_extension == \".jpeg\":\n",
    "                image_format = \"jpeg\"\n",
    "            elif file_extension == \".png\":\n",
    "                image_format = \"png\"\n",
    "            else:\n",
    "                image_format = \"jpeg\"  # default\n",
    "            \n",
    "            # Process with AI Foundry GPT-4o vision\n",
    "            from azure.ai.inference.models import SystemMessage, UserMessage, ImageContentItem, TextContentItem\n",
    "            \n",
    "            messages = [\n",
    "                SystemMessage(content=\"You are an expert insurance document analyzer. Extract ALL visible text from this insurance claim image with high accuracy. Structure the extracted information into clear categories: claim details, dates, amounts, policy numbers, damage descriptions, and any other relevant information. Preserve formatting and be thorough.\"),\n",
    "                UserMessage(content=[\n",
    "                    TextContentItem(text=\"Please extract and structure all text from this insurance claim image. Focus on claim numbers, dates, amounts, policy details, and damage descriptions.\"),\n",
    "                    ImageContentItem(image_url=f\"data:image/{image_format};base64,{base64_image}\")\n",
    "                ])\n",
    "            ]\n",
    "            \n",
    "            response = self.ai_client.complete(\n",
    "                model=Config.CHAT_MODEL_DEPLOYMENT,  # This should be gpt-4o-mini\n",
    "                messages=messages,\n",
    "                max_tokens=4000,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            extracted_text = response.choices[0].message.content\n",
    "            \n",
    "            metadata = {\n",
    "                \"file_name\": blob_name,\n",
    "                \"container\": container_name,\n",
    "                \"file_type\": \"image\",\n",
    "                \"image_format\": image_format,\n",
    "                \"image_size_bytes\": len(image_bytes),\n",
    "                \"text_length\": len(extracted_text),\n",
    "                \"processing_date\": pd.Timestamp.now().isoformat(),\n",
    "                \"model_used\": Config.CHAT_MODEL_DEPLOYMENT,\n",
    "                \"processing_type\": \"image_ocr\"\n",
    "            }\n",
    "                        \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"text\": extracted_text,\n",
    "                \"metadata\": metadata\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing image {blob_name}: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"metadata\": {\"file_name\": blob_name, \"container\": container_name, \"file_type\": \"image\"}\n",
    "            }\n",
    "    \n",
    "    def process_claim_images(self) -> List[Dict]:\n",
    "        \"\"\"Process all .jpg images in claims container\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        if not uploader:\n",
    "            print(\"‚ùå No uploader available - cannot process images\")\n",
    "            return results\n",
    "        \n",
    "        print(\"üñºÔ∏è Processing Claim Images with AI Foundry GPT-4o Vision...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        claims_blobs = uploader.list_blobs(Config.CLAIMS_CONTAINER)\n",
    "        image_blobs = [blob for blob in claims_blobs if blob.lower().endswith(('.jpg', '.jpeg'))]\n",
    "        \n",
    "        if not image_blobs:\n",
    "            print(\"‚ÑπÔ∏è No .jpg images found in claims container\")\n",
    "            return results\n",
    "        \n",
    "        for blob_name in tqdm(image_blobs, desc=\"Processing claim images\"):\n",
    "            result = self.extract_text_from_image(Config.CLAIMS_CONTAINER, blob_name)\n",
    "            results.append(result)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Processed {len(image_blobs)} claim images\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Image processor initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize image processor\n",
    "image_processor = None\n",
    "if ai_client and blob_service_client:\n",
    "    image_processor = ImageProcessor(ai_client, blob_service_client)\n",
    "    print(\"‚úÖ Image processor initialized!\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize image processor - missing clients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc6a63",
   "metadata": {},
   "source": [
    "## 5B. Text Document Processing\n",
    "Process .md files from policies container as text documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65941f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text processor initialized!\n"
     ]
    }
   ],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self, blob_service_client):\n",
    "        self.blob_service_client = blob_service_client\n",
    "    \n",
    "    def get_blob_content(self, container_name: str, blob_name: str) -> bytes:\n",
    "        \"\"\"Download blob content as bytes\"\"\"\n",
    "        if not self.blob_service_client:\n",
    "            raise Exception(\"No blob service client available\")\n",
    "            \n",
    "        blob_client = self.blob_service_client.get_blob_client(\n",
    "            container=container_name, \n",
    "            blob=blob_name\n",
    "        )\n",
    "        blob_data = blob_client.download_blob()\n",
    "        return blob_data.readall()\n",
    "    \n",
    "    def process_text_document(self, container_name: str, blob_name: str) -> Dict:\n",
    "        \"\"\"Process text document (markdown) for direct vectorization\"\"\"\n",
    "        try:\n",
    "            print(f\"üìÑ Processing text document: {blob_name}...\")\n",
    "            \n",
    "            # Download and decode content\n",
    "            blob_content = self.get_blob_content(container_name, blob_name)\n",
    "            content = blob_content.decode('utf-8')\n",
    "            \n",
    "            # Clean and prepare text for vectorization\n",
    "            # Remove excessive whitespace and normalize\n",
    "            cleaned_text = ' '.join(content.split())\n",
    "            \n",
    "            metadata = {\n",
    "                \"file_name\": blob_name,\n",
    "                \"container\": container_name,\n",
    "                \"file_type\": \"markdown\",\n",
    "                \"original_length\": len(content),\n",
    "                \"cleaned_length\": len(cleaned_text),\n",
    "                \"processing_date\": pd.Timestamp.now().isoformat(),\n",
    "                \"processing_type\": \"text_cleaning\"\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"text\": cleaned_text,\n",
    "                \"original_text\": content,\n",
    "                \"metadata\": metadata\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing text document {blob_name}: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"metadata\": {\"file_name\": blob_name, \"container\": container_name, \"file_type\": \"markdown\"}\n",
    "            }\n",
    "    \n",
    "    def process_policy_documents(self) -> List[Dict]:\n",
    "        \"\"\"Process all .md documents in policies container\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        if not uploader:\n",
    "            print(\"‚ùå No uploader available - cannot process documents\")\n",
    "            return results\n",
    "        \n",
    "        print(\"üìÑ Processing Policy Documents as Text...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        policy_blobs = uploader.list_blobs(Config.POLICIES_CONTAINER)\n",
    "        text_blobs = [blob for blob in policy_blobs if blob.lower().endswith('.md')]\n",
    "        \n",
    "        if not text_blobs:\n",
    "            print(\"‚ÑπÔ∏è No .md files found in policies container\")\n",
    "            return results\n",
    "        \n",
    "        for blob_name in tqdm(text_blobs, desc=\"Processing policy documents\"):\n",
    "            result = self.process_text_document(Config.POLICIES_CONTAINER, blob_name)\n",
    "            results.append(result)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Processed {len(text_blobs)} policy documents\")\n",
    "        return results\n",
    "\n",
    "# Initialize text processor\n",
    "text_processor = None\n",
    "if blob_service_client:\n",
    "    text_processor = TextProcessor(blob_service_client)\n",
    "    print(\"‚úÖ Text processor initialized!\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize text processor - missing blob client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5405584",
   "metadata": {},
   "source": [
    "## 5C. Azure AI Search Integration\n",
    "Set up Azure AI Search for vectorization using text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector search manager initialized!\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential as SearchKeyCredential\n",
    "\n",
    "class VectorSearchManager:\n",
    "    def __init__(self, ai_client):\n",
    "        self.ai_client = ai_client\n",
    "        self.search_endpoint = os.getenv('SEARCH_SERVICE_ENDPOINT', '').strip('\"')\n",
    "        self.search_key = os.getenv('SEARCH_ADMIN_KEY', '').strip('\"')\n",
    "        \n",
    "        if not self.search_endpoint or not self.search_key:\n",
    "            raise Exception(\"Missing Azure AI Search configuration\")\n",
    "        \n",
    "        self.search_credential = SearchKeyCredential(self.search_key)\n",
    "        self.index_client = SearchIndexClient(\n",
    "            endpoint=self.search_endpoint,\n",
    "            credential=self.search_credential\n",
    "        )\n",
    "        \n",
    "        # Index names\n",
    "        self.policies_index_name = \"insurance-policies-index\"\n",
    "        self.claims_index_name = \"insurance-claims-index\"\n",
    "    \n",
    "    def generate_embeddings(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embeddings using text-embedding-ada-002\"\"\"\n",
    "        try:\n",
    "            from azure.ai.inference.models import EmbeddingsInput\n",
    "            \n",
    "            response = self.ai_client.embed(\n",
    "                model=Config.EMBEDDING_MODEL_DEPLOYMENT,  # text-embedding-ada-002\n",
    "                input=[text]\n",
    "            )\n",
    "            \n",
    "            return response.data[0].embedding\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating embeddings: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_search_index(self, index_name: str, index_type: str):\n",
    "        \"\"\"Create search index for documents\"\"\"\n",
    "        try:\n",
    "            print(f\"üîç Creating search index: {index_name}...\")\n",
    "            \n",
    "            # Define fields based on index type\n",
    "            if index_type == \"policies\":\n",
    "                fields = [\n",
    "                    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "                    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "                    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"file_name\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"container\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"file_type\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"processing_date\", type=SearchFieldDataType.DateTimeOffset),\n",
    "                    SearchField(\n",
    "                        name=\"content_vector\",\n",
    "                        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                        searchable=True,\n",
    "                        vector_search_dimensions=1536,  # Ada-002 embedding size\n",
    "                        vector_search_profile_name=\"my-vector-config\"\n",
    "                    )\n",
    "                ]\n",
    "            else:  # claims\n",
    "                fields = [\n",
    "                    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "                    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "                    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"file_name\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"container\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"file_type\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"image_format\", type=SearchFieldDataType.String),\n",
    "                    SimpleField(name=\"processing_date\", type=SearchFieldDataType.DateTimeOffset),\n",
    "                    SearchField(\n",
    "                        name=\"content_vector\",\n",
    "                        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                        searchable=True,\n",
    "                        vector_search_dimensions=1536,  # Ada-002 embedding size\n",
    "                        vector_search_profile_name=\"my-vector-config\"\n",
    "                    )\n",
    "                ]\n",
    "            \n",
    "            # Configure vector search\n",
    "            vector_search = VectorSearch(\n",
    "                profiles=[\n",
    "                    VectorSearchProfile(\n",
    "                        name=\"my-vector-config\",\n",
    "                        algorithm_configuration_name=\"my-hnsw\"\n",
    "                    )\n",
    "                ],\n",
    "                algorithms=[\n",
    "                    HnswAlgorithmConfiguration(name=\"my-hnsw\")\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Create the search index\n",
    "            index = SearchIndex(\n",
    "                name=index_name,\n",
    "                fields=fields,\n",
    "                vector_search=vector_search\n",
    "            )\n",
    "            \n",
    "            result = self.index_client.create_or_update_index(index)\n",
    "            print(f\"‚úÖ Search index '{index_name}' created successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating search index: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def upload_documents_to_search(self, documents: List[Dict], index_name: str):\n",
    "        \"\"\"Upload documents with embeddings to Azure AI Search\"\"\"\n",
    "        try:\n",
    "            print(f\"üì§ Uploading documents to search index: {index_name}...\")\n",
    "            \n",
    "            search_client = SearchClient(\n",
    "                endpoint=self.search_endpoint,\n",
    "                index_name=index_name,\n",
    "                credential=self.search_credential\n",
    "            )\n",
    "            \n",
    "            search_documents = []\n",
    "            successful_uploads = 0\n",
    "            \n",
    "            for i, doc in enumerate(tqdm(documents, desc=\"Generating embeddings and uploading\")):\n",
    "                if not doc[\"success\"]:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Generate embeddings for the text content\n",
    "                    embeddings = self.generate_embeddings(doc[\"text\"])\n",
    "                    \n",
    "                    if not embeddings:\n",
    "                        print(f\"‚ö†Ô∏è Failed to generate embeddings for {doc['metadata']['file_name']}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Prepare document for search index\n",
    "                    search_doc = {\n",
    "                        \"id\": f\"{doc['metadata']['file_name']}_{i}\",\n",
    "                        \"title\": doc['metadata']['file_name'],\n",
    "                        \"content\": doc[\"text\"],\n",
    "                        \"file_name\": doc['metadata']['file_name'],\n",
    "                        \"container\": doc['metadata']['container'],\n",
    "                        \"file_type\": doc['metadata']['file_type'],\n",
    "                        \"processing_date\": doc['metadata']['processing_date'],\n",
    "                        \"content_vector\": embeddings\n",
    "                    }\n",
    "                    \n",
    "                    # Add image-specific fields for claims\n",
    "                    if index_name == self.claims_index_name and 'image_format' in doc['metadata']:\n",
    "                        search_doc[\"image_format\"] = doc['metadata']['image_format']\n",
    "                    \n",
    "                    search_documents.append(search_doc)\n",
    "                    successful_uploads += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error processing document {doc['metadata']['file_name']}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if search_documents:\n",
    "                # Upload documents in batches\n",
    "                batch_size = 10\n",
    "                for i in range(0, len(search_documents), batch_size):\n",
    "                    batch = search_documents[i:i + batch_size]\n",
    "                    result = search_client.upload_documents(documents=batch)\n",
    "                    print(f\"üì§ Uploaded batch {i//batch_size + 1}: {len(batch)} documents\")\n",
    "                \n",
    "                print(f\"‚úÖ Successfully uploaded {successful_uploads} documents to search index\")\n",
    "            else:\n",
    "                print(\"‚ùå No documents to upload\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading documents to search: {e}\")\n",
    "\n",
    "# Initialize vector search manager\n",
    "vector_search_manager = None\n",
    "if ai_client:\n",
    "    try:\n",
    "        vector_search_manager = VectorSearchManager(ai_client)\n",
    "        print(\"‚úÖ Vector search manager initialized!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cannot initialize vector search manager: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize vector search manager - missing AI client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5d576",
   "metadata": {},
   "source": [
    "## 6. Execute Processing Pipeline\n",
    "Process images and text documents, then vectorize into Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Complete Document Processing Pipeline...\n",
      "======================================================================\n",
      "\n",
      "==================================================\n",
      "STEP 1: Processing Claim Images\n",
      "==================================================\n",
      "üñºÔ∏è Processing Claim Images with AI Foundry GPT-4o Vision...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claim images:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Processing image: crash1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claim images:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:01,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing image crash1.jpg: (404) Resource not found\n",
      "Code: 404\n",
      "Message: Resource not found\n",
      "üñºÔ∏è Processing image: crash2.jpg...\n",
      "‚ùå Error processing image crash2.jpg: (404) Resource not found\n",
      "Code: 404\n",
      "Message: Resource not found\n",
      "üñºÔ∏è Processing image: crash3.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claim images:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing image crash3.jpg: (404) Resource not found\n",
      "Code: 404\n",
      "Message: Resource not found\n",
      "üñºÔ∏è Processing image: crash4.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing claim images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing image crash4.jpeg: (404) Resource not found\n",
      "Code: 404\n",
      "Message: Resource not found\n",
      "üñºÔ∏è Processing image: crash5.jpg...\n",
      "‚ùå Error processing image crash5.jpg: (404) Resource not found\n",
      "Code: 404\n",
      "Message: Resource not found\n",
      "\n",
      "‚úÖ Processed 5 claim images\n",
      "\n",
      "==================================================\n",
      "STEP 2: Processing Policy Text Documents\n",
      "==================================================\n",
      "üìÑ Processing Policy Documents as Text...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing policy documents:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing text document: commercial_auto_policy.md...\n",
      "üìÑ Processing text document: comprehensive_auto_policy.md...\n",
      "üìÑ Processing text document: high_value_vehicle_policy.md...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing policy documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing text document: liability_only_policy.md...\n",
      "üìÑ Processing text document: motorcycle_policy.md...\n",
      "\n",
      "‚úÖ Processed 5 policy documents\n",
      "\n",
      "==================================================\n",
      "STEP 3: Creating Search Indexes and Vectorizing\n",
      "==================================================\n",
      "üîç Creating search index: insurance-policies-index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Search index 'insurance-policies-index' created successfully\n",
      "üîç Creating search index: insurance-claims-index...\n",
      "‚úÖ Search index 'insurance-claims-index' created successfully\n",
      "\n",
      "üìö Vectorizing 5 policy documents...\n",
      "üì§ Uploading documents to search index: insurance-policies-index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings and uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1173.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "‚ö†Ô∏è Failed to generate embeddings for commercial_auto_policy.md\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "‚ö†Ô∏è Failed to generate embeddings for comprehensive_auto_policy.md\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "‚ö†Ô∏è Failed to generate embeddings for high_value_vehicle_policy.md\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "‚ö†Ô∏è Failed to generate embeddings for liability_only_policy.md\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "‚ö†Ô∏è Failed to generate embeddings for motorcycle_policy.md\n",
      "‚ùå No documents to upload\n",
      "\n",
      "üñºÔ∏è Vectorizing 5 claim documents...\n",
      "üì§ Uploading documents to search index: insurance-claims-index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings and uploading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 28966.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No documents to upload\n",
      "\n",
      "======================================================================\n",
      "üéâ PROCESSING PIPELINE COMPLETED!\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the complete processing pipeline\n",
    "print(\"üöÄ Starting Complete Document Processing Pipeline...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Process claim images with GPT-4o\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 1: Processing Claim Images\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "claim_results = []\n",
    "if image_processor:\n",
    "    claim_results = image_processor.process_claim_images()\n",
    "else:\n",
    "    print(\"‚ùå Image processor not available\")\n",
    "\n",
    "# Step 2: Process policy text documents\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 2: Processing Policy Text Documents\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "policy_results = []\n",
    "if text_processor:\n",
    "    policy_results = text_processor.process_policy_documents()\n",
    "else:\n",
    "    print(\"‚ùå Text processor not available\")\n",
    "\n",
    "# Step 3: Create search indexes and upload documents\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 3: Creating Search Indexes and Vectorizing\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if vector_search_manager:\n",
    "    # Create indexes\n",
    "    policies_index_created = vector_search_manager.create_search_index(\n",
    "        vector_search_manager.policies_index_name, \n",
    "        \"policies\"\n",
    "    )\n",
    "    \n",
    "    claims_index_created = vector_search_manager.create_search_index(\n",
    "        vector_search_manager.claims_index_name, \n",
    "        \"claims\"\n",
    "    )\n",
    "    \n",
    "    # Upload policy documents if index was created successfully\n",
    "    if policies_index_created and policy_results:\n",
    "        print(f\"\\nüìö Vectorizing {len(policy_results)} policy documents...\")\n",
    "        vector_search_manager.upload_documents_to_search(\n",
    "            policy_results, \n",
    "            vector_search_manager.policies_index_name\n",
    "        )\n",
    "    \n",
    "    # Upload claim documents if index was created successfully\n",
    "    if claims_index_created and claim_results:\n",
    "        print(f\"\\nüñºÔ∏è Vectorizing {len(claim_results)} claim documents...\")\n",
    "        vector_search_manager.upload_documents_to_search(\n",
    "            claim_results, \n",
    "            vector_search_manager.claims_index_name\n",
    "        )\n",
    "else:\n",
    "    print(\"‚ùå Vector search manager not available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ PROCESSING PIPELINE COMPLETED!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba3018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Results saved locally: complete_processing_results.json\n",
      "‚úÖ Uploaded: complete_processing_results.json ‚Üí processed-documents/complete_processing_results.json\n",
      "‚òÅÔ∏è Results uploaded to blob storage: processed-documents/complete_processing_results.json\n",
      "\n",
      "üìä FINAL PROCESSING SUMMARY:\n",
      "   üìÑ Policy Documents: 5/5 successful\n",
      "   üñºÔ∏è Claim Images: 0/5 successful\n",
      "   ü§ñ Text Model: gpt-4o-mini\n",
      "   üîç Embedding Model: text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Save processing results\n",
    "def save_processing_results():\n",
    "    \"\"\"Save all processing results to files\"\"\"\n",
    "    try:\n",
    "        # Combine results\n",
    "        all_results = {\n",
    "            \"policies\": policy_results,\n",
    "            \"claims\": claim_results,\n",
    "            \"processing_summary\": {\n",
    "                \"policies_processed\": len(policy_results),\n",
    "                \"policies_successful\": sum(1 for r in policy_results if r[\"success\"]),\n",
    "                \"claims_processed\": len(claim_results),\n",
    "                \"claims_successful\": sum(1 for r in claim_results if r[\"success\"]),\n",
    "                \"processing_date\": pd.Timestamp.now().isoformat(),\n",
    "                \"text_model\": Config.CHAT_MODEL_DEPLOYMENT,\n",
    "                \"embedding_model\": Config.EMBEDDING_MODEL_DEPLOYMENT\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save locally\n",
    "        output_file = \"complete_processing_results.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"üíæ Results saved locally: {output_file}\")\n",
    "        \n",
    "        # Upload to blob storage\n",
    "        if uploader:\n",
    "            success = uploader.upload_file(\n",
    "                Path(output_file), \n",
    "                Config.PROCESSED_CONTAINER, \n",
    "                output_file\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                print(f\"‚òÅÔ∏è Results uploaded to blob storage: {Config.PROCESSED_CONTAINER}/{output_file}\")\n",
    "        \n",
    "        return all_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving results: {e}\")\n",
    "        return None\n",
    "\n",
    "# Save the results\n",
    "final_results = save_processing_results()\n",
    "\n",
    "# Print summary\n",
    "if final_results:\n",
    "    summary = final_results[\"processing_summary\"]\n",
    "    print(f\"\\nüìä FINAL PROCESSING SUMMARY:\")\n",
    "    print(f\"   üìÑ Policy Documents: {summary['policies_successful']}/{summary['policies_processed']} successful\")\n",
    "    print(f\"   üñºÔ∏è Claim Images: {summary['claims_successful']}/{summary['claims_processed']} successful\")\n",
    "    print(f\"   ü§ñ Text Model: {summary['text_model']}\")\n",
    "    print(f\"   üîç Embedding Model: {summary['embedding_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff0d60",
   "metadata": {},
   "source": [
    "## 7. Test Search Functionality\n",
    "Test the vectorized search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a26820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Search Functionality...\n",
      "==================================================\n",
      "\n",
      "üîé Testing query: 'motorcycle insurance coverage'\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "   ‚ùå Failed to generate embeddings for query\n",
      "\n",
      "üîé Testing query: 'liability policy details'\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "   ‚ùå Failed to generate embeddings for query\n",
      "\n",
      "üîé Testing query: 'comprehensive coverage benefits'\n",
      "‚ùå Error generating embeddings: cannot import name 'EmbeddingsInput' from 'azure.ai.inference.models' (c:\\Users\\martasantos\\OneDrive - Microsoft\\FY26\\agentic-ai-hack\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\models\\__init__.py)\n",
      "   ‚ùå Failed to generate embeddings for query\n",
      "\n",
      "‚úÖ Search functionality test completed!\n"
     ]
    }
   ],
   "source": [
    "def test_search_functionality():\n",
    "    \"\"\"Test the search functionality with sample queries\"\"\"\n",
    "    if not vector_search_manager:\n",
    "        print(\"‚ùå Vector search manager not available\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç Testing Search Functionality...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        from azure.search.documents import SearchClient\n",
    "        \n",
    "        # Test policy search\n",
    "        policies_search_client = SearchClient(\n",
    "            endpoint=vector_search_manager.search_endpoint,\n",
    "            index_name=vector_search_manager.policies_index_name,\n",
    "            credential=vector_search_manager.search_credential\n",
    "        )\n",
    "        \n",
    "        # Test claims search\n",
    "        claims_search_client = SearchClient(\n",
    "            endpoint=vector_search_manager.search_endpoint,\n",
    "            index_name=vector_search_manager.claims_index_name,\n",
    "            credential=vector_search_manager.search_credential\n",
    "        )\n",
    "        \n",
    "        # Sample queries\n",
    "        test_queries = [\n",
    "            \"motorcycle insurance coverage\",\n",
    "            \"liability policy details\",\n",
    "            \"comprehensive coverage benefits\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\nüîé Testing query: '{query}'\")\n",
    "            \n",
    "            # Generate embedding for the query\n",
    "            query_embeddings = vector_search_manager.generate_embeddings(query)\n",
    "            \n",
    "            if query_embeddings:\n",
    "                # Search policies\n",
    "                try:\n",
    "                    vector_query = VectorizedQuery(vector=query_embeddings, k_nearest_neighbors=3, fields=\"content_vector\")\n",
    "                    policy_results = policies_search_client.search(\n",
    "                        search_text=\"\",\n",
    "                        vector_queries=[vector_query],\n",
    "                        select=[\"title\", \"content\", \"file_name\"],\n",
    "                        top=3\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"   üìÑ Policy Results:\")\n",
    "                    for result in policy_results:\n",
    "                        print(f\"     ‚Ä¢ {result['file_name']}: {result['content'][:100]}...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Policy search failed: {e}\")\n",
    "                \n",
    "                # Search claims\n",
    "                try:\n",
    "                    vector_query = VectorizedQuery(vector=query_embeddings, k_nearest_neighbors=3, fields=\"content_vector\")\n",
    "                    claim_results = claims_search_client.search(\n",
    "                        search_text=\"\",\n",
    "                        vector_queries=[vector_query],\n",
    "                        select=[\"title\", \"content\", \"file_name\"],\n",
    "                        top=3\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"   üñºÔ∏è Claim Results:\")\n",
    "                    for result in claim_results:\n",
    "                        print(f\"     ‚Ä¢ {result['file_name']}: {result['content'][:100]}...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Claim search failed: {e}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå Failed to generate embeddings for query\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Search functionality test completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing search functionality: {e}\")\n",
    "\n",
    "# Run the test\n",
    "test_search_functionality()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
