{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Processing with Azure OpenAI Multimodal Model\n",
    "\n",
    "This notebook handles:\n",
    "1. **Document Upload** - Upload policy and claims documents to Azure Blob Storage\n",
    "2. **Text Processing** - Process .md files using GPT-4o\n",
    "3. **OCR Processing** - Extract text from images using GPT-4o vision capabilities\n",
    "4. **Text Enhancement** - Clean and prepare documents for vectorization\n",
    "\n",
    "## Prerequisites\n",
    "- Azure Blob Storage account created\n",
    "- Azure OpenAI service with GPT-4o model deployed\n",
    "- Environment variables configured in `.env` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Azure SDK imports\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n",
    "# OpenAI imports\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully!\n",
      "üìÅ Policies directory: data\\policies\n",
      "üìÅ Claims directory: data\\claims\n",
      "ü§ñ OpenAI Deployment: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Storage configuration\n",
    "    AZURE_STORAGE_CONNECTION_STRING = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "    AZURE_STORAGE_ACCOUNT_NAME = os.getenv('AZURE_STORAGE_ACCOUNT_NAME')\n",
    "    AZURE_STORAGE_ACCOUNT_KEY = os.getenv('AZURE_STORAGE_ACCOUNT_KEY')\n",
    "    \n",
    "    # Azure OpenAI configuration\n",
    "    AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "    AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_KEY')\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION', '2024-02-15-preview')\n",
    "    AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME', 'gpt-4o-mini')\n",
    "    \n",
    "    # Container names\n",
    "    POLICIES_CONTAINER = 'policies'\n",
    "    CLAIMS_CONTAINER = 'claims'\n",
    "    PROCESSED_CONTAINER = 'processed-documents'\n",
    "    \n",
    "    # Local data paths\n",
    "    DATA_DIR = Path('data')\n",
    "    POLICIES_DIR = DATA_DIR / 'policies'\n",
    "    CLAIMS_DIR = DATA_DIR / 'claims'\n",
    "\n",
    "# Validate configuration\n",
    "required_vars = [\n",
    "    Config.AZURE_STORAGE_CONNECTION_STRING,\n",
    "    Config.AZURE_OPENAI_ENDPOINT,\n",
    "    Config.AZURE_OPENAI_API_KEY\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not var]\n",
    "if missing_vars:\n",
    "    print(\"‚ùå Missing environment variables. Please check your .env file.\")\n",
    "    print(\"Missing variables - please add these to your .env file:\")\n",
    "    if not Config.AZURE_OPENAI_ENDPOINT:\n",
    "        print(\"  - AZURE_OPENAI_ENDPOINT\")\n",
    "    if not Config.AZURE_OPENAI_API_KEY:\n",
    "        print(\"  - AZURE_OPENAI_API_KEY\")\n",
    "    if not Config.AZURE_STORAGE_CONNECTION_STRING:\n",
    "        print(\"  - AZURE_STORAGE_CONNECTION_STRING\")\n",
    "else:\n",
    "    print(\"‚úÖ Configuration loaded successfully!\")\n",
    "    print(f\"üìÅ Policies directory: {Config.POLICIES_DIR}\")\n",
    "    print(f\"üìÅ Claims directory: {Config.CLAIMS_DIR}\")\n",
    "    print(f\"ü§ñ OpenAI Deployment: {Config.AZURE_OPENAI_DEPLOYMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Azure Services Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure clients initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Azure clients\n",
    "def initialize_clients():\n",
    "    \"\"\"Initialize Azure service clients\"\"\"\n",
    "    try:\n",
    "        # Blob Storage client\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(\n",
    "            Config.AZURE_STORAGE_CONNECTION_STRING\n",
    "        )\n",
    "        \n",
    "        # Azure OpenAI client\n",
    "        openai_client = AzureOpenAI(\n",
    "            azure_endpoint=Config.AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=Config.AZURE_OPENAI_API_KEY,\n",
    "            api_version=Config.AZURE_OPENAI_API_VERSION\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Azure clients initialized successfully!\")\n",
    "        return blob_service_client, openai_client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error initializing clients: {e}\")\n",
    "        return None, None\n",
    "\n",
    "blob_service_client, openai_client = initialize_clients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running enhanced container creation...\n",
      "üîç Testing storage account connection...\n",
      "‚úÖ Connected to storage account successfully\n",
      "   Account kind: StorageV2\n",
      "   SKU name: Standard_LRS\n",
      "\n",
      "üîç Checking existing containers...\n",
      "‚úÖ Found 3 existing containers: ['claims', 'policies', 'processed-documents']\n",
      "‚ÑπÔ∏è Container 'policies' already exists\n",
      "‚ÑπÔ∏è Container 'claims' already exists\n",
      "‚ÑπÔ∏è Container 'processed-documents' already exists\n",
      "\n",
      "üìä Container Creation Summary:\n",
      "   ‚úÖ Successful: 3 - ['policies', 'claims', 'processed-documents']\n",
      "   ‚ùå Failed: 0 - []\n"
     ]
    }
   ],
   "source": [
    "# Enhanced container creation with multiple authentication methods and diagnostics\n",
    "def create_containers_enhanced(blob_service_client):\n",
    "    \"\"\"Create blob storage containers with enhanced error handling and diagnostics\"\"\"\n",
    "    \n",
    "    # First, test the connection\n",
    "    try:\n",
    "        print(\"üîç Testing storage account connection...\")\n",
    "        account_info = blob_service_client.get_account_information()\n",
    "        print(f\"‚úÖ Connected to storage account successfully\")\n",
    "        print(f\"   Account kind: {account_info.get('account_kind', 'Unknown')}\")\n",
    "        print(f\"   SKU name: {account_info.get('sku_name', 'Unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to connect to storage account: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test listing existing containers\n",
    "    try:\n",
    "        print(\"\\nüîç Checking existing containers...\")\n",
    "        existing_containers = []\n",
    "        for container in blob_service_client.list_containers():\n",
    "            existing_containers.append(container.name)\n",
    "        print(f\"‚úÖ Found {len(existing_containers)} existing containers: {existing_containers}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to list containers: {e}\")\n",
    "        print(\"   This might indicate insufficient permissions\")\n",
    "    \n",
    "    # Try to create containers\n",
    "    containers = [\n",
    "        Config.POLICIES_CONTAINER,\n",
    "        Config.CLAIMS_CONTAINER,\n",
    "        Config.PROCESSED_CONTAINER\n",
    "    ]\n",
    "    \n",
    "    created_containers = []\n",
    "    failed_containers = []\n",
    "    \n",
    "    for container_name in containers:\n",
    "        try:\n",
    "            # Check if container already exists first\n",
    "            container_client = blob_service_client.get_container_client(container_name)\n",
    "            \n",
    "            try:\n",
    "                # Try to get container properties (this will fail if it doesn't exist)\n",
    "                properties = container_client.get_container_properties()\n",
    "                print(f\"‚ÑπÔ∏è Container '{container_name}' already exists\")\n",
    "                created_containers.append(container_name)\n",
    "                continue\n",
    "            except Exception:\n",
    "                # Container doesn't exist, try to create it\n",
    "                pass\n",
    "            \n",
    "            # Create the container\n",
    "            print(f\"üî® Creating container '{container_name}'...\")\n",
    "            container_client.create_container()\n",
    "            print(f\"‚úÖ Container '{container_name}' created successfully\")\n",
    "            created_containers.append(container_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with container '{container_name}': {e}\")\n",
    "            failed_containers.append((container_name, str(e)))\n",
    "            \n",
    "            # Additional diagnostics for authorization errors\n",
    "            if \"AuthorizationFailure\" in str(e):\n",
    "                print(f\"   üîç Authorization issue detected for '{container_name}'\")\n",
    "                print(f\"   This could be due to:\")\n",
    "                print(f\"   - Storage account access keys disabled\")\n",
    "                print(f\"   - Network access restrictions\")\n",
    "                print(f\"   - Storage account permissions\")\n",
    "    \n",
    "    print(f\"\\nüìä Container Creation Summary:\")\n",
    "    print(f\"   ‚úÖ Successful: {len(created_containers)} - {created_containers}\")\n",
    "    print(f\"   ‚ùå Failed: {len(failed_containers)} - {[name for name, _ in failed_containers]}\")\n",
    "    \n",
    "    return len(failed_containers) == 0\n",
    "\n",
    "# Alternative: Try creating containers with different authentication methods\n",
    "def try_alternative_authentication():\n",
    "    \"\"\"Try alternative authentication methods for Azure Blob Storage\"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ Trying alternative authentication methods...\")\n",
    "    \n",
    "    # Method 1: Using account name and key directly\n",
    "    try:\n",
    "        from azure.storage.blob import BlobServiceClient\n",
    "        \n",
    "        account_name = Config.AZURE_STORAGE_ACCOUNT_NAME\n",
    "        account_key = Config.AZURE_STORAGE_ACCOUNT_KEY\n",
    "        \n",
    "        if account_name and account_key:\n",
    "            print(\"üîë Trying authentication with account name and key...\")\n",
    "            blob_service_client_alt = BlobServiceClient(\n",
    "                account_url=f\"https://{account_name}.blob.core.windows.net\",\n",
    "                credential=account_key\n",
    "            )\n",
    "            \n",
    "            # Test the connection\n",
    "            account_info = blob_service_client_alt.get_account_information()\n",
    "            print(\"‚úÖ Alternative authentication successful!\")\n",
    "            return blob_service_client_alt\n",
    "        else:\n",
    "            print(\"‚ùå Account name or key missing\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Alternative authentication failed: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Method 2: Manual container creation via Azure CLI (if available)\n",
    "def create_containers_via_cli():\n",
    "    \"\"\"Attempt to create containers using Azure CLI\"\"\"\n",
    "    import subprocess\n",
    "    import json\n",
    "    \n",
    "    print(\"\\nüîÑ Attempting container creation via Azure CLI...\")\n",
    "    \n",
    "    account_name = Config.AZURE_STORAGE_ACCOUNT_NAME\n",
    "    containers = ['policies', 'claims', 'processed-documents']\n",
    "    \n",
    "    for container in containers:\n",
    "        try:\n",
    "            # Try to create container using Azure CLI\n",
    "            cmd = [\n",
    "                'az', 'storage', 'container', 'create',\n",
    "                '--name', container,\n",
    "                '--account-name', account_name,\n",
    "                '--account-key', Config.AZURE_STORAGE_ACCOUNT_KEY,\n",
    "                '--public-access', 'off'\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ Container '{container}' created via CLI\")\n",
    "            else:\n",
    "                print(f\"‚ùå CLI failed for '{container}': {result.stderr}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå CLI method failed for '{container}': {e}\")\n",
    "\n",
    "# Run the enhanced container creation\n",
    "if blob_service_client:\n",
    "    print(\"üöÄ Running enhanced container creation...\")\n",
    "    success = create_containers_enhanced(blob_service_client)\n",
    "    \n",
    "    if not success:\n",
    "        print(\"\\nüîÑ Primary method failed, trying alternatives...\")\n",
    "        \n",
    "        # Try alternative authentication\n",
    "        alt_client = try_alternative_authentication()\n",
    "        if alt_client:\n",
    "            blob_service_client = alt_client\n",
    "            success = create_containers_enhanced(blob_service_client)\n",
    "        \n",
    "        # If still failing, suggest manual creation\n",
    "        if not success:\n",
    "            print(\"\\nüìù MANUAL CONTAINER CREATION REQUIRED\")\n",
    "            print(\"=\" * 50)\n",
    "            print(\"Please create the containers manually in Azure Portal:\")\n",
    "            print(\"1. Go to https://portal.azure.com\")\n",
    "            print(f\"2. Navigate to storage account: {Config.AZURE_STORAGE_ACCOUNT_NAME}\")\n",
    "            print(\"3. Go to 'Containers' in the left menu\")\n",
    "            print(\"4. Click '+ Container' and create these containers:\")\n",
    "            print(\"   - policies\")\n",
    "            print(\"   - claims\") \n",
    "            print(\"   - processed-documents\")\n",
    "            print(\"5. Set 'Public access level' to 'Private' for all containers\")\n",
    "            print(\"\\nAlternatively, try running this Azure CLI command:\")\n",
    "            print(f\"az storage container create --name policies --account-name {Config.AZURE_STORAGE_ACCOUNT_NAME}\")\n",
    "else:\n",
    "    print(\"‚ùå No blob service client available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Upload Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document uploader initialized!\n"
     ]
    }
   ],
   "source": [
    "class DocumentUploader:\n",
    "    def __init__(self, blob_service_client):\n",
    "        self.blob_service_client = blob_service_client\n",
    "    \n",
    "    def upload_file(self, file_path: Path, container_name: str, blob_name: str = None) -> bool:\n",
    "        \"\"\"Upload a single file to blob storage\"\"\"\n",
    "        if blob_name is None:\n",
    "            blob_name = file_path.name\n",
    "            \n",
    "        try:\n",
    "            blob_client = self.blob_service_client.get_blob_client(\n",
    "                container=container_name, \n",
    "                blob=blob_name\n",
    "            )\n",
    "            \n",
    "            with open(file_path, 'rb') as data:\n",
    "                blob_client.upload_blob(data, overwrite=True)\n",
    "            \n",
    "            print(f\"‚úÖ Uploaded: {file_path.name} ‚Üí {container_name}/{blob_name}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error uploading {file_path.name}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def upload_directory(self, directory_path: Path, container_name: str) -> Dict[str, bool]:\n",
    "        \"\"\"Upload all files from a directory to blob storage\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        if not directory_path.exists():\n",
    "            print(f\"‚ùå Directory not found: {directory_path}\")\n",
    "            return results\n",
    "        \n",
    "        files = list(directory_path.glob('*'))\n",
    "        if not files:\n",
    "            print(f\"‚ÑπÔ∏è No files found in {directory_path}\")\n",
    "            return results\n",
    "        \n",
    "        print(f\"üì§ Uploading {len(files)} files from {directory_path} to {container_name}...\")\n",
    "        \n",
    "        for file_path in tqdm(files, desc=\"Uploading files\"):\n",
    "            if file_path.is_file():\n",
    "                success = self.upload_file(file_path, container_name)\n",
    "                results[file_path.name] = success\n",
    "        \n",
    "        successful_uploads = sum(results.values())\n",
    "        print(f\"\\nüìä Upload Summary: {successful_uploads}/{len(results)} files uploaded successfully\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def list_blobs(self, container_name: str) -> List[str]:\n",
    "        \"\"\"List all blobs in a container\"\"\"\n",
    "        try:\n",
    "            container_client = self.blob_service_client.get_container_client(container_name)\n",
    "            blob_list = container_client.list_blobs()\n",
    "            return [blob.name for blob in blob_list]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error listing blobs in {container_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "# Initialize uploader\n",
    "if blob_service_client:\n",
    "    uploader = DocumentUploader(blob_service_client)\n",
    "    print(\"‚úÖ Document uploader initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Documents to Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Uploading Policy Documents...\n",
      "==================================================\n",
      "üì§ Uploading 5 files from data\\policies to policies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  20%|‚ñà‚ñà        | 1/5 [00:00<00:00,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: commercial_auto_policy.md ‚Üí policies/commercial_auto_policy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: comprehensive_auto_policy.md ‚Üí policies/comprehensive_auto_policy.md\n",
      "‚úÖ Uploaded: high_value_vehicle_policy.md ‚Üí policies/high_value_vehicle_policy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:00<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: liability_only_policy.md ‚Üí policies/liability_only_policy.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: motorcycle_policy.md ‚Üí policies/motorcycle_policy.md\n",
      "\n",
      "üìä Upload Summary: 5/5 files uploaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Policies in storage (5 files):\n",
      "  ‚Ä¢ commercial_auto_policy.md\n",
      "  ‚Ä¢ comprehensive_auto_policy.md\n",
      "  ‚Ä¢ high_value_vehicle_policy.md\n",
      "  ‚Ä¢ liability_only_policy.md\n",
      "  ‚Ä¢ motorcycle_policy.md\n"
     ]
    }
   ],
   "source": [
    "# Upload policy documents\n",
    "print(\"üìÑ Uploading Policy Documents...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "policy_results = uploader.upload_directory(Config.POLICIES_DIR, Config.POLICIES_CONTAINER)\n",
    "\n",
    "# Show uploaded policies\n",
    "policy_blobs = uploader.list_blobs(Config.POLICIES_CONTAINER)\n",
    "print(f\"\\nüìã Policies in storage ({len(policy_blobs)} files):\")\n",
    "for blob in policy_blobs:\n",
    "    print(f\"  ‚Ä¢ {blob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üñºÔ∏è Uploading Claims Documents...\n",
      "==================================================\n",
      "üì§ Uploading 6 files from data\\claims to claims...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:00<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: crash1.jpg ‚Üí claims/crash1.jpg\n",
      "‚úÖ Uploaded: crash2.jpg ‚Üí claims/crash2.jpg\n",
      "‚úÖ Uploaded: crash3.jpg ‚Üí claims/crash3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:00<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: crash4.jpeg ‚Üí claims/crash4.jpeg\n",
      "‚úÖ Uploaded: crash5.jpg ‚Üí claims/crash5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: invoice.png ‚Üí claims/invoice.png\n",
      "\n",
      "üìä Upload Summary: 6/6 files uploaded successfully\n",
      "\n",
      "üìã Claims in storage (6 files):\n",
      "  ‚Ä¢ crash1.jpg\n",
      "  ‚Ä¢ crash2.jpg\n",
      "  ‚Ä¢ crash3.jpg\n",
      "  ‚Ä¢ crash4.jpeg\n",
      "  ‚Ä¢ crash5.jpg\n",
      "  ‚Ä¢ invoice.png\n"
     ]
    }
   ],
   "source": [
    "# Upload claims documents\n",
    "print(\"\\nüñºÔ∏è Uploading Claims Documents...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "claims_results = uploader.upload_directory(Config.CLAIMS_DIR, Config.CLAIMS_CONTAINER)\n",
    "\n",
    "# Show uploaded claims\n",
    "claims_blobs = uploader.list_blobs(Config.CLAIMS_CONTAINER)\n",
    "print(f\"\\nüìã Claims in storage ({len(claims_blobs)} files):\")\n",
    "for blob in claims_blobs:\n",
    "    print(f\"  ‚Ä¢ {blob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Document Processing with Azure OpenAI GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the DocumentProcessor class methods with these updated versions:\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, openai_client, blob_service_client):\n",
    "        self.openai_client = openai_client\n",
    "        self.blob_service_client = blob_service_client\n",
    "    \n",
    "    def get_blob_content(self, container_name: str, blob_name: str) -> bytes:\n",
    "        \"\"\"Download blob content as bytes\"\"\"\n",
    "        blob_client = self.blob_service_client.get_blob_client(\n",
    "            container=container_name, \n",
    "            blob=blob_name\n",
    "        )\n",
    "        blob_data = blob_client.download_blob()\n",
    "        return blob_data.readall()\n",
    "    \n",
    "    def encode_image_to_base64(self, image_bytes: bytes) -> str:\n",
    "        \"\"\"Encode image bytes to base64 string\"\"\"\n",
    "        return base64.b64encode(image_bytes).decode('utf-8')\n",
    "    \n",
    "    def process_markdown_for_vectorization(self, container_name: str, blob_name: str) -> Dict:\n",
    "        \"\"\"Process markdown file for direct vectorization (no GPT-4o processing)\"\"\"\n",
    "        try:\n",
    "            print(f\"üìÑ Preparing markdown for vectorization: {blob_name}...\")\n",
    "            \n",
    "            # Download and decode content\n",
    "            blob_content = self.get_blob_content(container_name, blob_name)\n",
    "            content = blob_content.decode('utf-8')\n",
    "            \n",
    "            metadata = {\n",
    "                \"file_name\": blob_name,\n",
    "                \"container\": container_name,\n",
    "                \"file_type\": \"markdown\",\n",
    "                \"text_length\": len(content),\n",
    "                \"processing_date\": pd.Timestamp.now().isoformat(),\n",
    "                \"processing_method\": \"direct_vectorization\",\n",
    "                \"ready_for_embedding\": True\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"text\": content,  # Original markdown content for vectorization\n",
    "                \"metadata\": metadata\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {blob_name}: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"metadata\": {\"file_name\": blob_name, \"container\": container_name, \"file_type\": \"markdown\"}\n",
    "            }\n",
    "    def generate_image_description_with_gpt4o(self, container_name: str, blob_name: str) -> Dict:\n",
    "        try:\n",
    "            print(f\"üñºÔ∏è Generating description for image: {blob_name}...\")\n",
    "            \n",
    "            # Download image content\n",
    "            image_bytes = self.get_blob_content(container_name, blob_name)\n",
    "            base64_image = self.encode_image_to_base64(image_bytes)\n",
    "            \n",
    "            # Determine image format from file extension\n",
    "            file_extension = Path(blob_name).suffix.lower()\n",
    "            if file_extension == \".jpg\" or file_extension == \".jpeg\":\n",
    "                image_format = \"jpeg\"\n",
    "            elif file_extension == \".png\":\n",
    "                image_format = \"png\"\n",
    "            else:\n",
    "                image_format = \"jpeg\"  # default\n",
    "            \n",
    "            # Process with GPT-4o vision for description generation\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=Config.AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"\"\"You are an expert insurance claims analyst with advanced image analysis capabilities. \n",
    "                        Your task is to provide detailed, professional descriptions of insurance-related images, particularly vehicle damage and accident scenes.\n",
    "                        \n",
    "                        Focus on:\n",
    "                        - Type of vehicle and visible damage\n",
    "                        - Location and extent of damage (scratches, dents, broken parts, etc.)\n",
    "                        - Environmental context (road conditions, weather signs, location type)\n",
    "                        - Any visible people, other vehicles, or relevant objects\n",
    "                        - Overall severity assessment\n",
    "                        - Any safety concerns or hazards visible\n",
    "                        \n",
    "                        Provide clear, objective descriptions that would be useful for insurance claim processing and risk assessment.\"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Please provide a detailed description of this insurance claim image. Focus on damage assessment, environmental factors, and any relevant details for insurance processing.\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/{image_format};base64,{base64_image}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=4000,\n",
    "                temperature=0.3  # Slightly higher for more descriptive language\n",
    "            )\n",
    "            description = response.choices[0].message.content\n",
    "            \n",
    "            metadata = {\n",
    "                \"file_name\": blob_name,\n",
    "                \"container\": container_name,\n",
    "                \"file_type\": \"image\",\n",
    "                \"image_format\": image_format,\n",
    "                \"image_size_bytes\": len(image_bytes),\n",
    "                \"description_length\": len(description),\n",
    "                \"processing_date\": pd.Timestamp.now().isoformat(),\n",
    "                \"model_used\": Config.AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                \"processing_type\": \"image_description\",\n",
    "                \"ready_for_embedding\": True\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"description\": description,  # Changed from \"text\" to \"description\"\n",
    "                \"metadata\": metadata\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {blob_name}: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"metadata\": {\"file_name\": blob_name, \"container\": container_name, \"file_type\": \"image\"}\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def process_all_documents(self) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"Process documents: prepare markdown for vectorization, generate descriptions for images\"\"\"\n",
    "        results = {\n",
    "            \"policies\": [],\n",
    "            \"claims\": []\n",
    "        }\n",
    "        \n",
    "        # Process policy documents (markdown files) - prepare for vectorization only\n",
    "        print(\"üìÑ Preparing Policy Documents for Vectorization...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        policy_blobs = uploader.list_blobs(Config.POLICIES_CONTAINER)\n",
    "        for blob_name in tqdm(policy_blobs, desc=\"Preparing policies\"):\n",
    "            if blob_name.endswith(\".md\"):\n",
    "                result = self.process_markdown_for_vectorization(Config.POLICIES_CONTAINER, blob_name)\n",
    "                results[\"policies\"].append(result)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipping non-markdown file: {blob_name}\")\n",
    "        \n",
    "        # Process claims documents (images) - generate descriptions with GPT-4o Vision\n",
    "        print(\"\\nüñºÔ∏è Generating Image Descriptions with GPT-4o Vision...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        claims_blobs = uploader.list_blobs(Config.CLAIMS_CONTAINER)\n",
    "        for blob_name in tqdm(claims_blobs, desc=\"Generating descriptions\"):\n",
    "            if blob_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                result = self.generate_image_description_with_gpt4o(Config.CLAIMS_CONTAINER, blob_name)\n",
    "                results[\"claims\"].append(result)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipping non-image file: {blob_name}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_processed_results(self, results: Dict, output_file: str = \"processed_documents_for_vectorization.json\"):\n",
    "        \"\"\"Save processed results to JSON file and upload to blob storage\"\"\"\n",
    "        try:\n",
    "            # Save locally\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üíæ Results saved locally: {output_file}\")\n",
    "            \n",
    "            # Upload to blob storage\n",
    "            success = uploader.upload_file(\n",
    "                Path(output_file), \n",
    "                Config.PROCESSED_CONTAINER, \n",
    "                output_file\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                print(f\"‚òÅÔ∏è Results uploaded to blob storage: {Config.PROCESSED_CONTAINER}/{output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process All Documents with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document processor initialized with GPT-4o!\n",
      "\n",
      "üöÄ Starting document processing with GPT-4o...\n",
      "============================================================\n",
      "üìÑ Preparing Policy Documents for Vectorization...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing policies:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:00<00:00, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Preparing markdown for vectorization: commercial_auto_policy.md...\n",
      "üìÑ Preparing markdown for vectorization: comprehensive_auto_policy.md...\n",
      "üìÑ Preparing markdown for vectorization: high_value_vehicle_policy.md...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing policies: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Preparing markdown for vectorization: liability_only_policy.md...\n",
      "üìÑ Preparing markdown for vectorization: motorcycle_policy.md...\n",
      "\n",
      "üñºÔ∏è Generating Image Descriptions with GPT-4o Vision...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating descriptions:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Generating description for image: crash1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions:  17%|‚ñà‚ñã        | 1/6 [00:06<00:32,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Generating description for image: crash2.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:11<00:21,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Generating description for image: crash3.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [00:17<00:18,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Generating description for image: crash4.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [00:23<00:11,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Generating description for image: crash5.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [00:28<00:05,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Generating description for image: invoice.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:33<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Document processing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor with GPT-4o\n",
    "if openai_client and blob_service_client:\n",
    "    processor = DocumentProcessor(openai_client, blob_service_client)\n",
    "    print(\"‚úÖ Document processor initialized with GPT-4o!\")\n",
    "    \n",
    "    # Process documents using GPT-4o\n",
    "    print(\"\\nüöÄ Starting document processing with GPT-4o...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processing_results = processor.process_all_documents()\n",
    "    \n",
    "    print(\"\\n‚úÖ Document processing completed!\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize processor - missing clients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Results saved locally: processed_documents_for_vectorization.json\n",
      "‚úÖ Uploaded: processed_documents_for_vectorization.json ‚Üí processed-documents/processed_documents_for_vectorization.json\n",
      "‚òÅÔ∏è Results uploaded to blob storage: processed-documents/processed_documents_for_vectorization.json\n",
      "‚úÖ Uploaded: processing_summary_gpt4o.json ‚Üí processed-documents/processing_summary_gpt4o.json\n",
      "\n",
      "üíæ Summary report saved and uploaded!\n"
     ]
    }
   ],
   "source": [
    "# Save processing results\n",
    "processor.save_processed_results(processing_results)\n",
    "\n",
    "# Create a summary report\n",
    "report = {\n",
    "    \"processing_summary\": summary,\n",
    "    \"processing_date\": pd.Timestamp.now().isoformat(),\n",
    "    \"model_used\": Config.AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    \"processing_method\": \"gpt-4o_multimodal\",\n",
    "    \"successful_files\": {\n",
    "        \"policies\": [r[\"metadata\"][\"file_name\"] for r in processing_results[\"policies\"] if r[\"success\"]],\n",
    "        \"claims\": [r[\"metadata\"][\"file_name\"] for r in processing_results[\"claims\"] if r[\"success\"]]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"processing_summary_gpt4o.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "# Upload summary to blob storage\n",
    "uploader.upload_file(Path(\"processing_summary_gpt4o.json\"), Config.PROCESSED_CONTAINER)\n",
    "\n",
    "print(\"\\nüíæ Summary report saved and uploaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
